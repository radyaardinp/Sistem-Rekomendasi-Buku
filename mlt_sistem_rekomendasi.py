# -*- coding: utf-8 -*-
"""MLT_Sistem Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10iM0TAkt0ww4MCkINDT3-v46wdXx6NLM

Sistem Rekomendasi Buku

- Nama: Radya Ardi Ninang Pudyastuti
- Dataset: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset/data

----------------

# Import Library

Langkah pertama adalah melakukan import library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import kagglehub
import pickle
import os
import re
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np


import warnings
warnings.filterwarnings('ignore')

"""# Loading Dataset

Langkah selanjutnya adalah melakukan loading dataset yang berasal dari kaggle, kemudian dibaca ke dalam bentuk DataFrame Pandas.

Dari link tersebut, akan digunakan 2 dataset, yaitu book dan rating, untuk membangun content dan collaborative filtered book recommendation system.
"""

# Download latest version
path = kagglehub.dataset_download("arashnic/book-recommendation-dataset")
print("Path to dataset files:", path)

book = os.path.join(path, "Books.csv")
rating = os.path.join(path, "Ratings.csv")

"""menampilkan dataset book"""

df_book = pd.read_csv(book)
df_book

"""menampilkan dataset rating"""

df_rating = pd.read_csv(rating)
df_rating

"""# Eksplorasi Data Analysis (EDA)

##### Books

Pada tahap Eksplorasi Data atau Data Understanding akan dilakukan bertahap sesuai dengan dataset masing-masing. yang pertama adalah dataset books.

langkah pertama adalah memeriksa ukuran dimensi data untuk mengetahui berapa jumlah baris dan kolom pada dataset book.
"""

print(f'dimensi dataset buku:', df_book.shape)

"""memeriksa nilai yang hilang (missing value) pada dataset buku"""

#Missing value buku
df_book.isnull().sum()

"""memeriksa jumlah nilai yang duplikat pada judul buku (Book-Title) pada dataset."""

#Data duplikat
df_book.duplicated(["Book-Title"]).sum()

"""memeriksa tipe data pada setiap kolom"""

df_book.info()

"""melihat jumlah karya yang dihasilkan oleh penulis buku (Book-Author)"""

df_book['Book-Author'].value_counts().head(10)

"""melihat jumlah karya yang dihasilkan oleh suatu publisher"""

df_book['Publisher'].value_counts().head(10)

"""### Rating

memeriksa dimensi ukuran dataset rating
"""

print(f'dimensi dataset rating:', df_rating.shape)

"""memeriksa jumlah nilai yang hilang (missing value) pada dataset rating"""

df_rating.isnull().sum()

"""memeriksa nilai yang duplikat pada dataset rating"""

df_rating.duplicated().sum()

"""memeriksa tipe data pada setiap fitur kolom"""

df_rating.info()

"""menghitung jumlah buku berdasarkan ratingnya."""

df_rating['Book-Rating'].value_counts()

"""memeriksa pengguna yang memberikan rating terbanyak dalam dataset"""

df_rating['User-ID'].value_counts().head(10)

"""Menampilkan buku yang paling sering diberikan rating berdasarkan nomor ISBN."""

df_rating['ISBN'].value_counts().head(10)

"""# Data Preprocessing"""

books = df_book
ratings = df_rating

"""### Books

Langkah data preprocessing yang pertama pada dataset books adalah mengatasi missing value pada fitur Book-Author, Publisher, dan Image-URL-L.

pada kolom Book-Author, Publisher akan diisi dengan "Unknown". sedangkan pada kolom Image-URL-L, data yang kosong akan di drop, karena jumlahnya masih sedikit.
"""

#Mengisi missing value
books['Book-Author'].fillna('Unknown', inplace=True)
books['Publisher'].fillna('Unknown', inplace=True)
books.dropna(subset=['Image-URL-L'], inplace=True)

books.isnull().sum()

"""Langkah selanjutnya adalah menghapus data duplikat pada dataset books, agar tidak ada data yang redundan."""

books.duplicated().sum()
books.drop_duplicates(inplace=True)

books.duplicated().sum()

"""Mengubah kolom Year-Of-Publication menjadi tipe data numerik (int) dan membersihkan data tahun yang tidak valid."""

# mengubah Year-Of-Publication ke int
books['Year-Of-Publication'] = pd.to_numeric(books['Year-Of-Publication'], errors='coerce')
books = books[(books['Year-Of-Publication'] >= 1000) & (books['Year-Of-Publication'] <= 2025)]

"""Melakukan normalisasi teks dengan mengubah huruf menjadi lowercase dan menghapus spasi berlebih di awal/akhir string agar konsisten dalam format penulisan."""

# lowercase dan strip whitespace
books['Book-Title'] = books['Book-Title'].str.lower().str.strip()
books['Book-Author'] = books['Book-Author'].str.lower().str.strip()
books['Publisher'] = books['Publisher'].str.lower().str.strip()

books

"""Menyaring buku-buku populer yang telah mendapatkan lebih dari 50 rating."""

# Filter buku populer
popular_books = ratings['ISBN'].value_counts()
popular_isbn = popular_books[popular_books > 50].index
books_filtered = books[books['ISBN'].isin(popular_isbn)].drop_duplicates(subset='Book-Title')

"""Membuat fitur gabungan dari beberapa kolom informasi buku sebagai dasar analisis yang digunakan untuk proses transformasi teks dan pencocokan kemiripan antar buku dalam content-based filtering."""

# Menggabungkan fitur yang relevan
books_filtered['combined_features'] = (
    books_filtered['Book-Title'].fillna('') + ' ' +
    books_filtered['Book-Author'].fillna('') + ' ' +
    books_filtered['Publisher'].fillna('')
)

books_filtered

"""Mengubah teks gabungan menjadi representasi numerik menggunakan metode TF-IDF yang digunakan untuk proses pencocokan kemiripan antar buku dalam content-based filtering. Proses ini menghasilkan matriks fitur dari kata-kata penting yang merepresentasikan karakteristik tiap buku."""

# TF-IDF Vectorization
tfidf = TfidfVectorizer(stop_words='english', max_features=5000)

# Fit and transform the combined features
tfidf_matrix = tfidf.fit_transform(books_filtered['combined_features'])

# Now you can get the feature names (optional, but good for inspection)
feature_names = tfidf.get_feature_names_out()
feature_names

"""memeriksa dimensi matriks TF-IDF"""

# Fit and transform the combined features
tfidf_matrix = tfidf.fit_transform(books_filtered['combined_features'])
tfidf_matrix.shape

"""Mengonversi matriks TF-IDF dari format sparse matrix menjadi dense matrix"""

tfidf_matrix.todense()

"""Membuat DataFrame dari matriks TF-IDF dalam format dense, dengan baris berupa judul buku dan kolom berupa kata-kata fitur, lalu menampilkan sampel acak 10 kata dan 10 buku untuk eksplorasi data dan pemahaman terhadap representasi teks hasil vektorisasi."""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=books_filtered['Book-Title']
).sample(10, axis=1,replace=True).sample(10, axis=0)

"""Menghitung skor kemiripan antar buku berdasarkan cosine similarity dari matriks TF-IDF, yang digunakan untuk menentukan seberapa mirip satu buku dengan buku lainnya dalam content-based filtering. Hasilnya berupa matriks simetri dengan nilai antara 0 hingga 1."""

# Menghitung cosine similarity antar buku
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sim

"""Membuat indeks pencarian berdasarkan judul buku untuk mempermudah proses pencarian posisi buku tertentu dalam data. Indeks ini digunakan saat mengambil skor kemiripan dari matriks cosine similarity."""

# Membuat indeks pencarian berdasarkan judul
indices = pd.Series(range(len(books_filtered)), index=books_filtered['Book-Title']).drop_duplicates()

"""### Rating

Menghapus data rating dengan nilai 0 yang dianggap tidak merepresentasikan penilaian sebenarnya.
"""

#Menghapus rating 0
print(f"Sebelum dibersihkan: {df_rating.shape}")
ratings_cleaned = df_rating[df_rating['Book-Rating'] > 0]
print(f"Setelah dibersihkan: {ratings_cleaned.shape}")

"""Menyaring data rating agar hanya mencakup buku yang aktif (minimal 10 rating) dan pengguna yang aktif (minimal 5 rating)."""

active_books = ratings_cleaned['ISBN'].value_counts()[ratings_cleaned['ISBN'].value_counts() >= 10].index
active_users = ratings_cleaned['User-ID'].value_counts()[ratings_cleaned['User-ID'].value_counts() >= 5].index

ratings_filtered = ratings_cleaned[ratings_cleaned['ISBN'].isin(active_books) & ratings_cleaned['User-ID'].isin(active_users)]
ratings_filtered

"""Menyalin data rating hasil filtering dan melakukan encoding terhadap User-ID dan ISBN menjadi format angka dengan LabelEncoder, agar dapat digunakan dalam model collaborative filtering yang memerlukan input numerik"""

ratings = ratings_filtered.copy()

# Encode user dan book jadi integer index
from sklearn.preprocessing import LabelEncoder

user_enc = LabelEncoder()
book_enc = LabelEncoder()

"""Mengubah nilai asli User-ID dan ISBN menjadi representasi angka menggunakan hasil encoding, dan menyimpannya ke kolom baru (user dan book)."""

ratings['user'] = user_enc.fit_transform(ratings['User-ID'])
ratings['book'] = book_enc.fit_transform(ratings['ISBN'])

"""Menghitung jumlah unik pengguna (user) dan buku (book) dalam data rating. Informasi ini digunakan untuk mengetahui dimensi dari matriks interaksi user-item yang akan dibentuk dalam collaborative filtering."""

num_users = ratings['user'].nunique()
num_books = ratings['book'].nunique()

"""Memilih hanya kolom user, book, dan Book-Rating dari dataset untuk membentuk matriks interaksi yang merepresentasikan hubungan antara pengguna dan buku dalam collaborative filtering."""

ratings = ratings[['user', 'book', 'Book-Rating']]

"""Membagi data menjadi data latih dan data uji untuk mempersiapkan proses pelatihan dan evaluasi model dengan ratio 80:20"""

#Splitting data
X = ratings[['user', 'book']]
y = ratings['Book-Rating']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Pemodelan

Dalam proyek ini, sistem rekomendasi dibangun dengan memanfaatkan dua pendekatan utama, yaitu:
1. **Content-Based Filtering** memberikan rekomendasi berdasarkan kemiripan atribut antar item (dalam hal ini, buku). Sistem ini menganalisis fitur-fitur seperti penulis, judul, dan informasi buku lainnya, lalu mencari buku yang memiliki karakteristik serupa dengan buku yang disukai pengguna sebelumnya. Pendekatan ini tidak bergantung pada data dari pengguna lain, melainkan fokus pada konten dari item itu sendiri.
2. **Collaborative Filtering** memberikan rekomendasi berdasarkan perilaku pengguna lain. Sistem ini mengasumsikan bahwa jika dua pengguna memiliki selera yang mirip, maka buku yang disukai oleh satu pengguna kemungkinan juga disukai oleh pengguna lainnya. Pendekatan ini menggunakan interaksi antar pengguna dan item, tanpa memerlukan informasi detail dari konten buku itu sendiri.

-------------------
## Content Based Section

Membuat fungsi rekomendasi buku berdasarkan judul yang diberikan, dengan menggunakan skor kemiripan cosine antar buku. Fungsi ini akan mencari buku yang paling mirip (top N) dan mengembalikan informasi judul, penulis, dan penerbit sebagai hasil rekomendasi dalam content-based filtering.
"""

# Fungsi rekomendasi berdasarkan judul buku
def recommend_books(title, cosine_sim=cosine_sim, top_n=5):
    idx = indices.get(title)
    if idx is None:
        return ["Judul tidak ditemukan."]

    idx = int(idx)
    if idx >= cosine_sim.shape[0]:
        return ["Judul ditemukan, tetapi indeksnya tidak valid dalam matriks kesamaan."]


    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]
    book_indices = [i[0] for i in sim_scores]

    try:
        recommended_books_info = books_filtered.iloc[book_indices][['Book-Title', 'Book-Author', 'Publisher']]
    except IndexError:
        return ["Terjadi kesalahan saat mengambil informasi buku. Mungkin ada masalah dengan indeks buku yang direkomendasikan."]

    return recommended_books_info.reset_index(drop=True)

#Menyimpan model
pickle.dump(tfidf_matrix, open("tfidf_matrix.pkl", "wb"))
pickle.dump(cosine_sim, open("cosine_sim.pkl", "wb"))

"""Melakukan uji coba fungsi rekomendasi dengan input judul "american gods"."""

#uji coba model
recommend_books('american gods')

"""Berdasarkan hasil output uji coba model di atas, sistem berhasil menghasilkan daftar buku yang memiliki kemiripan konten, ditunjukkan dari kemunculan karya-karya lain dari penulis yang sama (Neil Gaiman), serta buku lain dengan karakteristik serupa. Hal ini menunjukkan bahwa model content-based filtering bekerja dengan baik dalam mengenali pola kemiripan berdasarkan informasi penulis, judul, dan penerbit.

----
## Collaborative Filtering

Membangun model collaborative filtering berbasis Neural Collaborative Filtering (NCF) dengan arsitektur neural network. Model ini menggunakan embedding untuk memetakan user dan item ke dalam vektor dimensi rendah, kemudian menggabungkannya dan melewatkannya ke layer dense untuk mempelajari pola interaksi yang kompleks antar pengguna dan buku. Model ini dikompilasi menggunakan fungsi loss mse (mean squared error) dan optimizer adam.
"""

#Membangun model Neural Network Model (NCF)
from tensorflow.keras.layers import Input, Embedding, Flatten, Concatenate, Dense, Dropout
from tensorflow.keras.models import Model

# Input
user_input = Input(shape=(1,))
book_input = Input(shape=(1,))

# Embedding
user_embedding = Embedding(num_users, 32)(user_input)
book_embedding = Embedding(num_books, 32)(book_input)

user_vec = Flatten()(user_embedding)
book_vec = Flatten()(book_embedding)

# Concatenate
concat = Concatenate()([user_vec, book_vec])
dense = Dense(128, activation='relu')(concat)
drop = Dropout(0.5)(dense)
output = Dense(1)(drop)

model = Model([user_input, book_input], output)
model.compile(loss='mse', optimizer='adam')
model.summary()

"""Melatih model neural collaborative filtering menggunakan data pelatihan selama 5 epoch dengan batch size 256."""

history = model.fit(
    [X_train['user'], X_train['book']],
    y_train,
    validation_data=([X_test['user'], X_test['book']], y_test),
    epochs=5,
    batch_size=256
)

"""Melakukan prediksi rating pada data uji menggunakan model yang telah dilatih, kemudian menghitung nilai RMSE (Root Mean Squared Error) sebagai metrik evaluasi"""

y_pred = model.predict([X_test['user'].values, X_test['book'].values])
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f'RMSE: {rmse:.4f}')

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.show()

"""Berdasarkan grafik di atas, model menunjukkan penurunan nilai loss pada data latih dan validasi seiring bertambahnya epoch, yang mengindikasikan bahwa model berhasil belajar dan tidak mengalami overfitting. Perbedaan nilai yang kecil antara train loss dan validation loss juga menunjukkan kestabilan performa model.

----
Selanjutnya adalah membuat fungsi rekomendasi buku berbasis collaborative filtering dengan input user_id. Fungsi ini akan mengidentifikasi buku-buku yang belum pernah diberi rating oleh pengguna tersebut, kemudian memprediksi rating potensial menggunakan model yang telah dilatih. Buku-buku dengan prediksi tertinggi akan direkomendasikan, dan hasilnya dikembalikan dalam bentuk daftar judul dan penulis. Pendekatan ini merekomendasikan buku berdasarkan pola interaksi pengguna lain yang mirip.
"""

def recommend_books(user_id, model, ratings_df, book_df, top_n=10):
    # Encode user_id asli ke index
    try:
        user_idx = user_enc.transform([user_id])[0]
    except:
        print("User tidak ditemukan.")
        return

    # Buku yang sudah diberi rating oleh user
    rated_books = ratings_df[ratings_df['user'] == user_idx]['book'].tolist()

    # Daftar semua buku
    all_books = np.arange(num_books)

    # Buku yang belum dirating
    unrated_books = np.setdiff1d(all_books, rated_books)

    # Buat prediksi
    user_input = np.full(len(unrated_books), user_idx)
    book_input = unrated_books

    predictions = model.predict([user_input, book_input], verbose=0)
    top_indices = predictions.flatten().argsort()[-top_n:][::-1]
    top_book_indices = unrated_books[top_indices]

    # Decode book index ke ISBN
    recommended_isbns = book_enc.inverse_transform(top_book_indices)

    # Ambil judul buku
    recommended_titles = book_df[book_df['ISBN'].isin(recommended_isbns)][['ISBN', 'Book-Title', 'Book-Author']]
    return recommended_titles.drop_duplicates('ISBN').head(top_n)

"""selanjutnya menyimpan model"""

#Save the trained model
model.save('collaborative_filtering_model.h5')

# You might also want to save the label encoders
with open('user_encoder.pkl', 'wb') as f:
    pickle.dump(user_enc, f)

with open('book_encoder.pkl', 'wb') as f:
    pickle.dump(book_enc, f)

"""Melakukan uji coba fungsi rekomendasi dengan memasukkan user_id tertentu. Sistem akan memprediksi rating dari buku-buku yang belum pernah dibaca oleh user tersebut, lalu menampilkan 5 buku teratas dengan prediksi rating tertinggi."""

#Contoh penggunaan
user_sample_id = 276747
recommend_books(user_sample_id, model, ratings, books, top_n=5)

"""berdasarkan hasil uji coba di atas, sistem  rekomendasi collaborative filltering menunjukkan lima buku teratas yang diprediksi paling relevan untuk user dengan ID 276747. Buku-buku yang direkomendasikan mencakup karya populer seperti “The Ultimate Hitchhiker’s Guide” oleh Douglas Adams, beberapa komik Calvin & Hobbes oleh Bill Watterson, serta novel klasik seperti “A Little Princess” dan “Pride and Prejudice”. Ini mengindikasikan bahwa sistem collaborative filtering mampu menangkap preferensi pengguna berdasarkan pola interaksi pengguna lain yang serupa.

# Kesimpulan

Dalam sistem rekomendasi ini digunakan dua metode, yaitu Content-Based Filtering dan Collaborative Filtering. Content-based merekomendasikan buku berdasarkan kemiripan konten seperti judul dan penulis, cocok untuk rekomendasi personal terutama bagi pengguna baru. Sementara itu, collaborative filtering memanfaatkan pola rating pengguna lain untuk memprediksi preferensi, sehingga mampu memberikan rekomendasi yang lebih variatif. Kombinasi keduanya menghasilkan sistem yang lebih akurat, relevan, dan sesuai dengan kebutuhan pengguna.
"""